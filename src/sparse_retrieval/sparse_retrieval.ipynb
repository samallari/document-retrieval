{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c5544e97656202",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Sparse Retrieval\n",
    "Implementation of sparse passage retrieval using TF-IDF and BM25. Evaluated on the MS MARCO dataset using MRR and retrieval time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feac61983cfb2265",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef58e8d4077932f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load MSMARCO dataset\n",
    "dataset = load_dataset(\"ms_marco\", \"v2.1\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5a7dfa-c49c-4b87-b239-18c48838aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_cell = True\n",
    "if not skip_cell:\n",
    "    # display dataset information\n",
    "    print(\"Train dataset size:\", len(train_dataset))\n",
    "    print(\"Validation dataset size:\", len(eval_dataset))\n",
    "    print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "    # print column labels\n",
    "    print(\"Train dataset columns:\", train_dataset.column_names, \"\\n\")\n",
    "\n",
    "    # print sample from the train dataset\n",
    "    for col in train_dataset.column_names:\n",
    "        print(f\"Sample {col}: {train_dataset[0][col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0cdfbf-57c2-44b1-8a2b-7b5a765a0f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example:\n",
      "Query: )what was the immediate impact of the success of the manhattan project?\n",
      "Passage: The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the MS MARCO dataset, extracting queries and passages.\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    passages = []\n",
    "    # For training data, we need to extract queries and positive passages\n",
    "    if \"answers\" in data.features:\n",
    "        for item in data:\n",
    "            queries.append(item[\"query\"])\n",
    "            # In training, we will use the first passage as the positive passage.\n",
    "            # in test and validation, we would need to do this differently.\n",
    "            if len(item[\"passages\"][\"passage_text\"]) > 0:\n",
    "                passages.extend(item[\"passages\"][\"passage_text\"])\n",
    "\n",
    "    # For validation and test, we need to extract only queries and passages\n",
    "    else:\n",
    "        for item in data:\n",
    "            queries.append(item[\"query\"])\n",
    "            if len(item[\"passages\"][\"passage_text\"]) > 0:\n",
    "                passages.extend(item[\"passages\"][\"passage_text\"])\n",
    "    return queries, passages\n",
    "\n",
    "# Preprocess the train, validation, and test datasets\n",
    "train_queries, train_passages = preprocess(train_dataset)\n",
    "validation_queries, validation_passages = preprocess(eval_dataset)\n",
    "test_queries, test_passages = preprocess(test_dataset)\n",
    "\n",
    "# Example of the first training query and passage\n",
    "print(\"\\nExample:\")\n",
    "print(f\"Query: {train_queries[0]}\")\n",
    "print(f\"Passage: {train_passages[0]}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3ff9c-eeff-42d9-8534-69a69dec7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseRetriever:\n",
    "    def __init__(self, passages):\n",
    "        self.passages = passages\n",
    "        self.tokenized_passages = [p.lower().split() for p in passages]\n",
    "        \n",
    "    def build_indices(self):\n",
    "        # TF-IDF\n",
    "        self.tfidf = TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        self.tfidf_vectors = self.tfidf.fit_transform(self.passages)\n",
    "        \n",
    "        # BM25\n",
    "        self.bm25 = BM25Okapi(self.tokenized_passages)\n",
    "    \n",
    "    def tfidf_search(self, query, top_k=10):\n",
    "        query_vec = self.tfidf.transform([query])\n",
    "        scores = np.squeeze(query_vec.dot(self.tfidf_vectors.T).toarray())\n",
    "            \n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        return top_indices, scores[top_indices]\n",
    "\n",
    "    def bm25_search(self, query, top_k=10):\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "            \n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        return top_indices, scores[top_indices]\n",
    "\n",
    "retriever = SparseRetriever(train_passages)\n",
    "retriever.build_indices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
