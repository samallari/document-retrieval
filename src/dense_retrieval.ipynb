{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dense Retrieval\n",
    "Implementation of dense passage retrieval using DistilBERT and FAISS. Evaluated on the MS MARCO dataset using MRR and retrieval time.\n"
   ],
   "id": "337d670bef39b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "c4a3a069c56effd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:05.791988Z",
     "start_time": "2025-05-08T20:07:02.135585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_loader import DatasetLoader\n",
    "\n",
    "# Load cranfield dataset for testing functions, use MS MARCO, HotpotQA, and potentially Climate-FEVER for real evaluation\n",
    "loader = DatasetLoader(\"cranfield\")\n",
    "docs, queries, qrels = loader.get_all()\n",
    "loader.print_info()\n",
    "\n",
    "# # load multiple datasets for evaluation\n",
    "# nameset = [\"beir/msmarco/dev\", \"bier/hotpotqa/dev\", \"bier/climate-fever/dev\"]\n",
    "#\n",
    "# # Dictionary to hold datasets\n",
    "# datasets = {}\n",
    "#\n",
    "# for name in nameset:\n",
    "#     loader = DatasetLoader(name)\n",
    "#     docs, queries, qrels = loader.get_all()\n",
    "#     datasets[name] = {\n",
    "#         \"docs\": docs,\n",
    "#         \"queries\": queries,\n",
    "#         \"qrels\": qrels\n",
    "#     }\n",
    "#     loader.print_info()\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: cranfield\n",
      "DOCS (1400): ('1', 'experimental investigation of the aerodynamics of a\\nwing in a slipstream .\\n  an experimental study of a wing in a propeller slipstream was\\nmade in order to determine the spanwise distribution of the lift\\nincrease due to slipstream at different angles of attack of the wing\\nand at different free stream to slipstream velocity ratios .  the\\nresults were intended in part as an evaluation basis for different\\ntheoretical treatments of this problem .\\n  the comparative span loading curves, together with\\nsupporting evidence, showed that a substantial part of the lift increment\\nproduced by the slipstream was due to a /destalling/ or\\nboundary-layer-control effect .  the integrated remaining lift\\nincrement, after subtracting this destalling lift, was found to agree\\nwell with a potential flow theory .\\n  an empirical evaluation of the destalling effects was made for\\nthe specific configuration of the experiment .') \n",
      "\n",
      "QUERIES (225): ('1', 'what similarity laws must be obeyed when constructing aeroelastic models\\nof heated high speed aircraft .') \n",
      "\n",
      "QRELS (225): ('1', {'195': 4, '142': 4, '52': 4, '462': 4, '13': 4, '14': 4, '15': 4, '56': 3, '95': 3, '30': 3, '185': 3, '858': 3, '66': 3, '876': 3, '102': 3, '51': 3, '12': 3, '879': 3, '880': 3, '37': 3, '497': 3, '184': 2, '859': 2, '378': 2, '57': 2, '31': 2, '29': 2, '875': 2, '486': -1}) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "27689d18561fefeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:05.914690Z",
     "start_time": "2025-05-08T20:07:05.911579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract document and query IDs + texts for embedding\n",
    "doc_ids, doc_texts = list(docs.keys()), list(docs.values())\n",
    "query_ids, query_texts = list(queries.keys()), list(queries.values())\n",
    "#\n",
    "# print(doc_ids[:5])\n",
    "# print(doc_texts[:5])\n",
    "#\n",
    "# print(query_ids[:5])\n",
    "# print(query_texts[:5])\n"
   ],
   "id": "81e00d907f865a81",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Document Embedding",
   "id": "3be1476ef6e7ca04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:43.143321Z",
     "start_time": "2025-05-08T20:07:05.931586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "import torch\n",
    "# load encoder model pretrained on MS MARCO\n",
    "model_name = \"msmarco-MiniLM-L6-cos-v5\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 32 if device == \"cuda\" else 16\n",
    "model.eval() # put in eval mode to speed up inference\n",
    "\n",
    "# encode documents and queries\n",
    "document_embeddings = model.encode(doc_texts,\n",
    "                                    batch_size=batch_size,\n",
    "                                    convert_to_tensor=True,\n",
    "                                    device=device,\n",
    "                                    show_progress_bar=True,\n",
    "                                    normalize_embeddings=True)\n",
    "query_embeddings = model.encode(query_texts,\n",
    "                                batch_size=batch_size,\n",
    "                                convert_to_tensor=True,\n",
    "                                device=device,\n",
    "                                show_progress_bar=True,\n",
    "                                normalize_embeddings=True)\n",
    "\n",
    "# convert to numpy array for FAISS\n",
    "# doc_embs = document_embeddings.cpu().numpy().astype(\"float32\")\n",
    "# query_embs = query_embeddings.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "# convert to ubinary to save memory space\n",
    "doc_embs = quantize_embeddings(document_embeddings, \"ubinary\")\n",
    "query_embs = quantize_embeddings(query_embeddings, \"ubinary\")"
   ],
   "id": "39aac114369a4200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a4dae469b8646bfacc985e10e99c3f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b1aafd3be2141178734255b0410ead2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b388823320a48f497794622fb0b9132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1852a17e126411995cb0ff9c751b297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a96f242eca094c489000e9f8f0b00835"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b05af57c62a14b888df58b4f782a85f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "023f32df59d849e5a981d84c75ba5a87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dcf537547004219a407556e059d6f8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c89647e8355c40eaa7283096b46f2c1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4a261ba8438464287af8d9ea43da4a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19b5a54bdb9a4a99a94dd9d3b1d7d36f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/88 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ebafbc1c3d34f3bb58d347e6c610096"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d664319f9f74fd88d2b8b35f1471d52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build FAISS Index",
   "id": "4eddcf3b18d99939"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:56.785659Z",
     "start_time": "2025-05-08T20:07:56.781097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "\n",
    "# normalize embeddings with faiss\n",
    "# faiss.normalize_L2(doc_embs)\n",
    "# faiss.normalize_L2(query_embs)\n",
    "\n",
    "# build index, use cosine similarity\n",
    "dim = doc_embs.shape[1]\n",
    "print(dim)\n",
    "\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(doc_embs)\n",
    "print(index.ntotal)\n"
   ],
   "id": "6427809a7fb07cd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "1400\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:43.350446Z",
     "start_time": "2025-05-07T05:57:50.581621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(doc_embs.shape)\n",
    "print(query_embs.shape)"
   ],
   "id": "5b7adf1790c1aa74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 768)\n",
      "(225, 768)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "d67c58a609d8787a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieval Time",
   "id": "a3d42d5ca82d091c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:08:20.724333Z",
     "start_time": "2025-05-08T20:08:00.993410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# do KNN Search and return retrieval time\n",
    "k = 10\n",
    "start_time = time.time()\n",
    "distances, indices = index.search(query_embs, k)\n",
    "retrieval_time = (time.time() - start_time) / len(query_ids)\n",
    "print(f\"Retrieval time per query: {retrieval_time:.6f} seconds\")"
   ],
   "id": "f2e4b89791c2f550",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:07:43.364533Z",
     "start_time": "2025-05-07T05:57:50.620835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "# k = 10\n",
    "# batch_size = 32  # Tune based on available RAM\n",
    "# num_queries = query_embs.shape[1]\n",
    "# all_distances = []\n",
    "# all_indices = []\n",
    "#\n",
    "# for i in tqdm(range(0, num_queries, batch_size)):\n",
    "#     end = min(i + batch_size, num_queries)\n",
    "#     query_batch = query_embs[i:end]\n",
    "#\n",
    "#     # FAISS search for the batch\n",
    "#     distances, indices = index.search(query_batch, k)\n",
    "#\n",
    "#     all_distances.append(distances)\n",
    "#     all_indices.append(indices)\n",
    "#\n",
    "# # Concatenate results\n",
    "# all_distances = np.vstack(all_distances)\n",
    "# all_indices = np.vstack(all_indices)"
   ],
   "id": "cff9150ea30724a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mean Reciprocal Rank (MRR)",
   "id": "2b73ff489de39052"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ranx import Run, evaluate\n",
    "\n",
    "# calculate MRR\n",
    "\n",
    "# Run: stores the relevance scores estimated by the model under evaluation\n",
    "# map results for each query_id -> { doc_id: score }\n",
    "run = {\n",
    "    query_ids[i]: {\n",
    "        doc_ids[indices[i][j]]: float(distances[i][j]) for j in range(k)\n",
    "    }\n",
    "    for i in range(len(query_ids))\n",
    "}\n",
    "\n",
    "# convert to Run object\n",
    "run_rx = Run(run)\n",
    "run_rx.save(\"dense_run.json\")\n",
    "\n",
    "# measure MRR\n",
    "mrr = evaluate(qrels, run_rx, \"mrr\", make_comparable=True)\n",
    "print(f\"MRR: {mrr:.4f}\")\n"
   ],
   "id": "35ff9ccd078436fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
